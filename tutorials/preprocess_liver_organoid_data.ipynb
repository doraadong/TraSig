{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T16:41:16.433652Z",
     "start_time": "2018-01-21T16:41:16.401450Z"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T20:24:46.797093Z",
     "start_time": "2018-01-22T20:24:45.944027Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocces the liver organoid data (DesLO) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will preprocess the liver organoid data (DesLO) and obtain the filtered and normalized expression, combined from multiple time points. We format the output expression data in the CSHMM input file format:\n",
    "    * The 1st row is the header. \n",
    "    * Each row is a cell. \n",
    "        * The 1st column is the name of the cell. The 2nd column is the sampled time of the cell. The 3rd column is the label (cell type) of the cell. All the other columns are the gene expression.\n",
    "        \n",
    "The inputs required are the original count matrices for the scRNA-seq data and can be downloaded from the repository GSE159491 as we noted in the paper. These files have the following structure:\n",
    "    * sample name (e.g. mmB_DesLo_D17)\n",
    "        * barcodes.tsv  \n",
    "        * genes.tsv\n",
    "        * matrix.mtx\n",
    "\n",
    "You also need the following files from our GitHub website:\n",
    "    * R script read_10x_save_csv.R, given we will also preprocess the data in R. \n",
    "    * .csv files holding the annotations from Seurat for each time point, e.g. DesLO_D17_Cluster.csv. There are three of them, each for the data from a single time point. You can find them at tutorials/annotations folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: use Seurat in R to filter and normalize the expression data for each time point\n",
    "\n",
    "    1. In R, run read_10x_save_csv.R to filter low-quality genes and cells, normalize the data and to obtain the .csv format expression data. \n",
    "        * R packages: Seurat(3.2.2) ,dplyr(1.0.2), data.table(1.13.2) are required for this step.  \n",
    "        * The output files will be saved in .csv format, e.g. mmB_DesLO_D17.csv. After this step, you should has 3 .csv files: mmB_D5.csv, mmB_DesLO_D11.csv and mmB_DesLO_D17.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: assign annotations and combine data from multiple time points "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 read in data from each time point and assign annotations to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_known = True\n",
    "convert2order = True\n",
    "parent_path = \"~/\"\n",
    "condition = \"\"\n",
    "features = None\n",
    "\n",
    "dict_times = {'':[5],\n",
    "         'DesLO_': [11,17]}\n",
    "\n",
    "time2order = {'D5': 1,\n",
    "              'DesLO_D11': 3,\n",
    "              'DesLO_D17': 4}\n",
    "\n",
    "experiments = ['','DesLO_']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = \"/mnt/5eaf9992-fb1d-44ee-8ab5-a16d8b70d7d5/archive/research/cshmm-before-July21/DesLO/temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []  # original IDs associated with cells \n",
    "id_list = []\n",
    "time_list = []\n",
    "label_list = []\n",
    "exp_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in experiments:\n",
    "    times = dict_times[experiment]\n",
    "    \n",
    "    for time in times:\n",
    "        dataname =  experiment + 'D' + str(time)\n",
    "        folder = \"mmB_\" + dataname\n",
    "\n",
    "        suffix = condition\n",
    "        filename = \"mmB_\" + dataname + suffix + \".csv\"\n",
    "        _path = os.path.join(parent_path, \"input/expression/\")\n",
    "        expression = pd.read_csv(os.path.join(_path, filename))\n",
    "\n",
    "        # read in gene names once \n",
    "        if features is None:\n",
    "            _path = os.path.join(parent_path, \"input/expression/raw\")\n",
    "            try:\n",
    "                feature_file = os.path.join(_path, folder, \"genes.tsv\")\n",
    "                features = pd.read_csv(feature_file, header = None)\n",
    "            except IOError:\n",
    "                feature_file = os.path.join(_path, folder, \"features.tsv\")\n",
    "                features = pd.read_csv(feature_file, header = None)\n",
    "\n",
    "            features = features.iloc[:,0].values # turn to numpy \n",
    "        \n",
    "        if 'Expression' in features[0]: # remove Gene Expression tag \n",
    "            features = np.array(['\\t'.join(l.split('\\t')[:2]) for l in features])\n",
    "        \n",
    "        # prepare labels \n",
    "        if label_known:\n",
    "            # read labels \n",
    "            _path = os.path.join(parent_path, \"input/expression/\")\n",
    "            suffix = \"Cluster.csv\"\n",
    "            filename = '_'.join([dataname, suffix])\n",
    "            labels = pd.read_csv(os.path.join(_path, filename))\n",
    "            labels.columns = ['name','label']\n",
    "            if '-' in labels['name'][0]:\n",
    "                labels['name'] = [c.split('-')[0] for c in labels['name']]\n",
    "\n",
    "            # get cell names for the expression \n",
    "            cell_names = expression.columns.values\n",
    "            cell_names = np.array([c.split('-') for c in cell_names])\n",
    "            all_names = pd.DataFrame(cell_names)\n",
    "            all_names['index'] = all_names.index\n",
    "            all_names.columns = ['name','batch','index']\n",
    "            assert len(set(all_names['batch'])) == 1  # all same batch\n",
    "\n",
    "            # only use the cells overlapped in both the expression and the annotation file  \n",
    "            merged = pd.merge(all_names, labels, on = 'name')\n",
    "            id_selected = merged['name'] + '-' + merged['batch']\n",
    "            \n",
    "            expression = expression[id_selected]\n",
    "            \n",
    "            # same ordering in expression as in meta/label file\n",
    "            assert all(expression.columns.values == id_selected)\n",
    "\n",
    "            label_subset = merged['label'].values\n",
    "        else:\n",
    "            temp = np.empty(n_cells)  # no label is known\n",
    "            temp[:] = np.nan\n",
    "            label_subset = list(temp)    \n",
    "            \n",
    "        n_gene = expression.shape[0]\n",
    "        n_cells = expression.shape[1]\n",
    "        \n",
    "        # prepare meta data \n",
    "        id_subset = [dataname + '_' + str(i) for i in range(n_cells)]\n",
    "        if convert2order:\n",
    "            time_subset = np.repeat(time2order[dataname], n_cells)\n",
    "        else:\n",
    "            time_subset = np.repeat(time, n_cells)\n",
    "        \n",
    "        if time == 5:  # use WT cells in D5 as D0  \n",
    "            # get ID for D0\n",
    "            idx_d0 = merged['index'][merged['label'] == 'WT'].values\n",
    "            \n",
    "            # mark as D0 instead of D5\n",
    "            time_subset[idx_d0] = 0\n",
    "            \n",
    "        # convert to numpy \n",
    "        temp = expression.T\n",
    "            \n",
    "        name_list.append(id_selected)\n",
    "        id_list.append(id_subset)\n",
    "        time_list.append(list(time_subset))\n",
    "        label_list.append(label_subset)\n",
    "        exp_list.append(temp.values)  # list of numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 process feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_datasets = len(exp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# take only gene names; if same gene name then attach with code \n",
    "gene_names = [f.split('\\t')[1] for f in features]\n",
    "gene_codes = [f.split('\\t')[0] for f in features]\n",
    "\n",
    "unique, counts = np.unique(np.array(gene_names), return_counts=True)\n",
    "print(counts[counts > 1])\n",
    "\n",
    "gList = []\n",
    "g_D = {}\n",
    "for i in range(len(gene_names)):\n",
    "    g = gene_names[i]\n",
    "    c = gene_codes[i]\n",
    "    if g in g_D:\n",
    "        gList.append(g + '_' + c)\n",
    "    else:\n",
    "        g_D[g] = 1\n",
    "        gList.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = np.array(gList)\n",
    "exp_list_common = exp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 combine datasets  and save output\n",
    "1. remove lowly expressed genes \n",
    "2. assemble into CSHMM / SCDIFF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    \n",
    "def combine_meta_save(subsets, df, nz_genes):\n",
    "    _id = flatten(list(id_list[i] for i in subsets))\n",
    "    _time = flatten(list(time_list[i] for i in subsets))\n",
    "    _label = flatten(list(label_list[i] for i in subsets))\n",
    "\n",
    "    df['ID'] = _id\n",
    "    df['time'] = _time\n",
    "    df['label'] = _label\n",
    "\n",
    "    columns = list(nz_genes) + ['ID','time','label'] \n",
    "    df.columns = columns\n",
    "\n",
    "    columns = ['ID','time','label']  + list(nz_genes)\n",
    "    df = df[columns]\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_subsets = ['DesLO']\n",
    "dict_subsets = {'DesLO': [0,1,2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in name_subsets:\n",
    "    subsets = dict_subsets[name]\n",
    "    _exp = np.concatenate(list(exp_list_common[i] for i in subsets))\n",
    "    \n",
    "    # remove 0 count genes\n",
    "    _sum = _exp.sum(axis=0)\n",
    "    zero_genes = gene_names[_sum==0]\n",
    "    nz_genes = [x for x in gene_names if x not in zero_genes]\n",
    "    temp = list(gene_names)\n",
    "    nz_genes_idx = [temp.index(g) for g in nz_genes] \n",
    "    \n",
    "    # filter expression\n",
    "    _exp = _exp[:,nz_genes_idx]  \n",
    "    _exp = pd.DataFrame(_exp)\n",
    "    \n",
    "    filename = ''.join([name, '.txt'])\n",
    "    df = combine_meta_save(subsets, _exp, nz_genes)\n",
    "    \n",
    "    # remove other day 5 cells\n",
    "    df = df[df['time'] != 1]\n",
    "    df.to_csv(os.path.join(parent_path, filename), sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cshmm] *",
   "language": "python",
   "name": "conda-env-cshmm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
